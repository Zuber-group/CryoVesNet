{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train 3D Unet for vesicle segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook trains a 3D Unet deep learning network with vesicle segmentation data. The training set is created in the [create_training](create_training.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import cryovesnet\n",
    "#from keras import backend as K\n",
    "#K.set_image_data_format('channels_last')\n",
    "\n",
    "# import unetmic.unetmic as umic\n",
    "import cryovesnet.unetmic.unetmic.unetmic as umic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if GPU is available2\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__[0] == '1':\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    tf.keras.backend.set_session(tf.Session(config=config))\n",
    "    print('Check if GPU is available')\n",
    "    print(tf.test.gpu_device_name())\n",
    "else:\n",
    "    print('Check if GPU is available2')\n",
    "    print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available: True\n"
     ]
    }
   ],
   "source": [
    "# TF 2Check if a GPU is available\n",
    "gpu_available = tf.config.list_physical_devices('GPU')\n",
    "print(\"Is GPU available:\", len(gpu_available) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#create the 3d-unet\n",
    "# unet3d = umic.create_unet_3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netowrk2d = umic.create_unet_2d(128,network_name = 'eman2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/media/amin/mtwo/train_dataset_2d_128_synaptasome_1000/'\n",
    "save_folder = '/media/amin/mtwo/train2d/'\n",
    "\n",
    "#specify number of training data, validation data, batch size\n",
    "numtot = 4062\n",
    "numvalid = 475\n",
    "batchsize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/backend.py:6818: StrategyBase.configure (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use `update_config_proto` instead.\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /home/amin/PycharmProjects/CryoVesNetNEW/cryovesnet/unetmic/unetmic/unetmic.py:314: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/amin/PycharmProjects/CryoVesNetNEW/cryovesnet/unetmic/unetmic/unetmic.py:314: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/tensorflow/python/distribute/v1/input_lib.py:197: DistributedIteratorV1.initialize (from tensorflow.python.distribute.v1.input_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the iterator's `initializer` property instead.\n",
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/distribute/distributed_training_utils_v1.py:328: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use `experimental_local_results` instead.\n",
      "Train on 40.0 steps, validate on 4.0 steps\n",
      "Epoch 1/1000\n",
      " 3/40 [=>............................] - ETA: 4s - batch: 1.0000 - size: 1.0000 - loss: 1.9824 - dice_coef: 0.1513    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 21:54:40.311417: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:192] cuptiSubscribe: error 35: CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2024-04-30 21:54:40.311455: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2024-04-30 21:54:40.311466: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2024-04-30 21:54:40.363296: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2024-04-30 21:54:40.363330: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2024-04-30 21:54:40.363343: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2024-04-30 21:54:40.365197: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 6s 71ms/step - batch: 19.5000 - size: 1.0000 - loss: 1.3592 - dice_coef: 0.1758 - val_loss: 1.3579 - val_dice_coef: 0.2212\n",
      "Epoch 2/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 1.2093 - dice_coef: 0.2073 - val_loss: 1.1533 - val_dice_coef: 0.2769\n",
      "Epoch 3/1000\n",
      "40/40 [==============================] - 2s 59ms/step - batch: 19.5000 - size: 1.0000 - loss: 1.1074 - dice_coef: 0.2384 - val_loss: 1.0498 - val_dice_coef: 0.3073\n",
      "Epoch 4/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 1.0445 - dice_coef: 0.2572 - val_loss: 1.0182 - val_dice_coef: 0.3551\n",
      "Epoch 5/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.9829 - dice_coef: 0.2794 - val_loss: 0.8715 - val_dice_coef: 0.4243\n",
      "Epoch 6/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.8879 - dice_coef: 0.3106 - val_loss: 0.7394 - val_dice_coef: 0.4584\n",
      "Epoch 7/1000\n",
      "40/40 [==============================] - 2s 61ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.8370 - dice_coef: 0.3323 - val_loss: 0.7141 - val_dice_coef: 0.5127\n",
      "Epoch 8/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.8035 - dice_coef: 0.3470 - val_loss: 0.6662 - val_dice_coef: 0.4846\n",
      "Epoch 9/1000\n",
      "40/40 [==============================] - 2s 59ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7848 - dice_coef: 0.3535 - val_loss: 0.6567 - val_dice_coef: 0.5124\n",
      "Epoch 10/1000\n",
      "40/40 [==============================] - 3s 65ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7709 - dice_coef: 0.3637 - val_loss: 0.6658 - val_dice_coef: 0.5074\n",
      "Epoch 11/1000\n",
      "40/40 [==============================] - 2s 59ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7535 - dice_coef: 0.3697 - val_loss: 0.6290 - val_dice_coef: 0.5015\n",
      "Epoch 12/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7442 - dice_coef: 0.3744 - val_loss: 0.6942 - val_dice_coef: 0.5710\n",
      "Epoch 13/1000\n",
      "40/40 [==============================] - 2s 61ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7520 - dice_coef: 0.3730 - val_loss: 0.6245 - val_dice_coef: 0.5097\n",
      "Epoch 14/1000\n",
      "40/40 [==============================] - 2s 59ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7391 - dice_coef: 0.3781 - val_loss: 0.6070 - val_dice_coef: 0.5396\n",
      "Epoch 15/1000\n",
      "40/40 [==============================] - 2s 61ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7190 - dice_coef: 0.3885 - val_loss: 0.5984 - val_dice_coef: 0.5590\n",
      "Epoch 16/1000\n",
      "40/40 [==============================] - 2s 59ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7149 - dice_coef: 0.3872 - val_loss: 0.6127 - val_dice_coef: 0.5694\n",
      "Epoch 17/1000\n",
      "40/40 [==============================] - 2s 59ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6987 - dice_coef: 0.3968 - val_loss: 0.6077 - val_dice_coef: 0.5724\n",
      "Epoch 18/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7079 - dice_coef: 0.3918 - val_loss: 0.5972 - val_dice_coef: 0.5878\n",
      "Epoch 19/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.7049 - dice_coef: 0.3949 - val_loss: 0.5763 - val_dice_coef: 0.5249\n",
      "Epoch 20/1000\n",
      "40/40 [==============================] - 2s 59ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6998 - dice_coef: 0.3985 - val_loss: 0.5866 - val_dice_coef: 0.5517\n",
      "Epoch 21/1000\n",
      "40/40 [==============================] - 2s 59ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6876 - dice_coef: 0.3990 - val_loss: 0.5851 - val_dice_coef: 0.5724\n",
      "Epoch 22/1000\n",
      "40/40 [==============================] - 2s 59ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6855 - dice_coef: 0.4041 - val_loss: 0.5725 - val_dice_coef: 0.5447\n",
      "Epoch 23/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6872 - dice_coef: 0.4012 - val_loss: 0.6112 - val_dice_coef: 0.6001\n",
      "Epoch 24/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6716 - dice_coef: 0.4111 - val_loss: 0.5628 - val_dice_coef: 0.5774\n",
      "Epoch 25/1000\n",
      "40/40 [==============================] - 2s 60ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6714 - dice_coef: 0.4070 - val_loss: 0.6164 - val_dice_coef: 0.6018\n",
      "Epoch 26/1000\n",
      "40/40 [==============================] - 2s 58ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6666 - dice_coef: 0.4126 - val_loss: 0.5687 - val_dice_coef: 0.5801\n",
      "Epoch 27/1000\n",
      "40/40 [==============================] - 3s 66ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6678 - dice_coef: 0.4093 - val_loss: 0.6133 - val_dice_coef: 0.5962\n",
      "Epoch 28/1000\n",
      "40/40 [==============================] - 2s 58ms/step - batch: 19.5000 - size: 1.0000 - loss: 0.6618 - dice_coef: 0.4140 - val_loss: 0.6052 - val_dice_coef: 0.6123\n",
      "Epoch 29/1000\n",
      "26/40 [==================>...........] - ETA: 0s - batch: 12.5000 - size: 1.0000 - loss: 0.6608 - dice_coef: 0.4182"
     ]
    }
   ],
   "source": [
    "umic.run_training_multiGPU_2d(save_folder = save_folder, data_folder = folder, \n",
    "                              num_total = numtot,batch_size = batchsize, num_valid = numvalid,network_name=\"eman2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "unet3d = umic.create_unet_3d(inputsize=(32, 32, 32, 1),\n",
    "                   n_depth=2,\n",
    "                   n_filter_base=16,\n",
    "                   kernel_size=(3, 3, 3),\n",
    "                   activation='relu',\n",
    "                   batch_norm=True,\n",
    "                   dropout=0.1,\n",
    "                   n_conv_per_depth=2,\n",
    "                   pool_size=(2, 2, 2),\n",
    "                   n_channel_out=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#specifiy path to training data and to folder where to save training weights\n",
    "folder = '/mnt/data/Amin/Data/train_dataset_synaptosome32/'\n",
    "save_folder = '/mnt/data/Amin/Data/cryo_learning/'\n",
    "\n",
    "#specify number of training data, validation data, batch size\n",
    "numtot = 950\n",
    "numvalid = 150\n",
    "batchsize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 7s 244ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.4897 - dice_coef: 0.2424 - val_loss: 0.5614 - val_dice_coef: 0.2825\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 4s 205ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.3522 - dice_coef: 0.3298 - val_loss: 1.3447 - val_dice_coef: 0.3073\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 4s 204ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.2908 - dice_coef: 0.4309 - val_loss: 0.9638 - val_dice_coef: 0.3848\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 4s 203ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.2500 - dice_coef: 0.4989 - val_loss: 0.4855 - val_dice_coef: 0.4725\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 4s 217ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.2267 - dice_coef: 0.5301 - val_loss: 0.3426 - val_dice_coef: 0.5318\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 4s 221ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.2098 - dice_coef: 0.5606 - val_loss: 0.3516 - val_dice_coef: 0.5430\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 4s 213ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1968 - dice_coef: 0.5884 - val_loss: 0.3402 - val_dice_coef: 0.5516\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 4s 219ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1826 - dice_coef: 0.6100 - val_loss: 0.2821 - val_dice_coef: 0.5885\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 4s 222ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1715 - dice_coef: 0.6378 - val_loss: 0.2113 - val_dice_coef: 0.6373\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 4s 235ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1642 - dice_coef: 0.6506 - val_loss: 0.1920 - val_dice_coef: 0.6529\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 4s 204ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1570 - dice_coef: 0.6654 - val_loss: 0.1732 - val_dice_coef: 0.6665\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 4s 208ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1500 - dice_coef: 0.6792 - val_loss: 0.1659 - val_dice_coef: 0.6784\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 4s 211ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1446 - dice_coef: 0.6920 - val_loss: 0.1671 - val_dice_coef: 0.6999\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 4s 208ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1430 - dice_coef: 0.6970 - val_loss: 0.2044 - val_dice_coef: 0.5964\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 4s 218ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1382 - dice_coef: 0.7058 - val_loss: 0.1573 - val_dice_coef: 0.7176\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 4s 205ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1323 - dice_coef: 0.7185 - val_loss: 0.1730 - val_dice_coef: 0.6958\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 4s 205ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1275 - dice_coef: 0.7279 - val_loss: 0.1956 - val_dice_coef: 0.6594\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 4s 219ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1209 - dice_coef: 0.7401 - val_loss: 0.2242 - val_dice_coef: 0.6229\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 4s 208ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1197 - dice_coef: 0.7443 - val_loss: 0.1614 - val_dice_coef: 0.7209\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 4s 208ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1154 - dice_coef: 0.7515 - val_loss: 0.1711 - val_dice_coef: 0.7096\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 4s 198ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1104 - dice_coef: 0.7632 - val_loss: 0.2044 - val_dice_coef: 0.6528\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 4s 199ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1055 - dice_coef: 0.7735 - val_loss: 0.1819 - val_dice_coef: 0.7173\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 4s 213ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1040 - dice_coef: 0.7737 - val_loss: 0.1673 - val_dice_coef: 0.7329\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 4s 238ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.1009 - dice_coef: 0.7826 - val_loss: 0.1650 - val_dice_coef: 0.7722\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 4s 214ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0981 - dice_coef: 0.7887 - val_loss: 0.1661 - val_dice_coef: 0.7522\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 4s 199ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0945 - dice_coef: 0.7948 - val_loss: 0.1734 - val_dice_coef: 0.7410\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 4s 199ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0900 - dice_coef: 0.8058 - val_loss: 0.1645 - val_dice_coef: 0.7690\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0904 - dice_coef: 0.8047 - val_loss: 0.1505 - val_dice_coef: 0.7705\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 4s 199ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0897 - dice_coef: 0.8077 - val_loss: 0.1726 - val_dice_coef: 0.7850\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 4s 198ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0889 - dice_coef: 0.8100 - val_loss: 0.2210 - val_dice_coef: 0.6937\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 4s 198ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0846 - dice_coef: 0.8174 - val_loss: 0.1520 - val_dice_coef: 0.8029\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 4s 208ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0816 - dice_coef: 0.8241 - val_loss: 0.1605 - val_dice_coef: 0.7617\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 4s 208ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0825 - dice_coef: 0.8220 - val_loss: 0.1409 - val_dice_coef: 0.7999\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 4s 214ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0792 - dice_coef: 0.8305 - val_loss: 0.1596 - val_dice_coef: 0.7767\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 4s 213ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0761 - dice_coef: 0.8368 - val_loss: 0.1574 - val_dice_coef: 0.7859\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0747 - dice_coef: 0.8388 - val_loss: 0.1697 - val_dice_coef: 0.7750\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0777 - dice_coef: 0.8355 - val_loss: 0.1519 - val_dice_coef: 0.7987\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0745 - dice_coef: 0.8404 - val_loss: 0.1580 - val_dice_coef: 0.7946\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0696 - dice_coef: 0.8496 - val_loss: 0.1788 - val_dice_coef: 0.7744\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0681 - dice_coef: 0.8540 - val_loss: 0.1663 - val_dice_coef: 0.7969\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0679 - dice_coef: 0.8548 - val_loss: 0.1635 - val_dice_coef: 0.7882\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0688 - dice_coef: 0.8531 - val_loss: 0.1896 - val_dice_coef: 0.7641\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0673 - dice_coef: 0.8568 - val_loss: 0.1658 - val_dice_coef: 0.7988\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0662 - dice_coef: 0.8582 - val_loss: 0.2044 - val_dice_coef: 0.7624\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0679 - dice_coef: 0.8558 - val_loss: 0.1764 - val_dice_coef: 0.8072\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0678 - dice_coef: 0.8574 - val_loss: 0.2082 - val_dice_coef: 0.7721\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0637 - dice_coef: 0.8633 - val_loss: 0.1619 - val_dice_coef: 0.8047\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0618 - dice_coef: 0.8685 - val_loss: 0.1817 - val_dice_coef: 0.7864\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0623 - dice_coef: 0.8676 - val_loss: 0.1726 - val_dice_coef: 0.7936\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0660 - dice_coef: 0.8605 - val_loss: 0.2030 - val_dice_coef: 0.7828\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0621 - dice_coef: 0.8678 - val_loss: 0.1723 - val_dice_coef: 0.8002\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0597 - dice_coef: 0.8731 - val_loss: 0.1619 - val_dice_coef: 0.8130\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0598 - dice_coef: 0.8724 - val_loss: 0.1761 - val_dice_coef: 0.8049\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0585 - dice_coef: 0.8759 - val_loss: 0.1804 - val_dice_coef: 0.8011\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0591 - dice_coef: 0.8751 - val_loss: 0.1604 - val_dice_coef: 0.8163\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0578 - dice_coef: 0.8769 - val_loss: 0.2252 - val_dice_coef: 0.7648\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0561 - dice_coef: 0.8802 - val_loss: 0.2057 - val_dice_coef: 0.7835\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0545 - dice_coef: 0.8840 - val_loss: 0.1641 - val_dice_coef: 0.8246\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0547 - dice_coef: 0.8834 - val_loss: 0.1726 - val_dice_coef: 0.8094\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0543 - dice_coef: 0.8843 - val_loss: 0.1722 - val_dice_coef: 0.8156\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0544 - dice_coef: 0.8836 - val_loss: 0.1690 - val_dice_coef: 0.8144\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0529 - dice_coef: 0.8878 - val_loss: 0.1710 - val_dice_coef: 0.8198\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0509 - dice_coef: 0.8910 - val_loss: 0.1669 - val_dice_coef: 0.8245\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0517 - dice_coef: 0.8904 - val_loss: 0.2005 - val_dice_coef: 0.7959\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0520 - dice_coef: 0.8897 - val_loss: 0.1759 - val_dice_coef: 0.8213\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0554 - dice_coef: 0.8835 - val_loss: 0.1951 - val_dice_coef: 0.8149\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0579 - dice_coef: 0.8799 - val_loss: 0.1789 - val_dice_coef: 0.7966\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0569 - dice_coef: 0.8786 - val_loss: 0.2074 - val_dice_coef: 0.7963\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0534 - dice_coef: 0.8863 - val_loss: 0.2274 - val_dice_coef: 0.7747\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0501 - dice_coef: 0.8932 - val_loss: 0.1742 - val_dice_coef: 0.8215\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0498 - dice_coef: 0.8941 - val_loss: 0.1836 - val_dice_coef: 0.8173\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0482 - dice_coef: 0.8972 - val_loss: 0.1759 - val_dice_coef: 0.8198\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0491 - dice_coef: 0.8960 - val_loss: 0.1947 - val_dice_coef: 0.8022\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0482 - dice_coef: 0.8972 - val_loss: 0.1974 - val_dice_coef: 0.8161\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0476 - dice_coef: 0.8989 - val_loss: 0.1828 - val_dice_coef: 0.8244\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0476 - dice_coef: 0.8988 - val_loss: 0.1973 - val_dice_coef: 0.8051\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0484 - dice_coef: 0.8976 - val_loss: 0.1903 - val_dice_coef: 0.8198\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0482 - dice_coef: 0.8979 - val_loss: 0.1884 - val_dice_coef: 0.8214\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0469 - dice_coef: 0.8994 - val_loss: 0.1932 - val_dice_coef: 0.8172\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0467 - dice_coef: 0.9002 - val_loss: 0.1869 - val_dice_coef: 0.8224\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0462 - dice_coef: 0.9020 - val_loss: 0.2051 - val_dice_coef: 0.8023\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0457 - dice_coef: 0.9030 - val_loss: 0.1926 - val_dice_coef: 0.8216\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0446 - dice_coef: 0.9046 - val_loss: 0.2053 - val_dice_coef: 0.8024\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0443 - dice_coef: 0.9054 - val_loss: 0.1879 - val_dice_coef: 0.8262\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0440 - dice_coef: 0.9071 - val_loss: 0.1967 - val_dice_coef: 0.8166\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0452 - dice_coef: 0.9040 - val_loss: 0.2127 - val_dice_coef: 0.7896\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0448 - dice_coef: 0.9049 - val_loss: 0.1947 - val_dice_coef: 0.8189\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0452 - dice_coef: 0.9045 - val_loss: 0.2148 - val_dice_coef: 0.7968\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0442 - dice_coef: 0.9052 - val_loss: 0.1805 - val_dice_coef: 0.8266\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0440 - dice_coef: 0.9072 - val_loss: 0.1815 - val_dice_coef: 0.8295\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0426 - dice_coef: 0.9088 - val_loss: 0.1921 - val_dice_coef: 0.8280\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0444 - dice_coef: 0.9069 - val_loss: 0.2027 - val_dice_coef: 0.8161\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0445 - dice_coef: 0.9056 - val_loss: 0.2024 - val_dice_coef: 0.8161\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0451 - dice_coef: 0.9044 - val_loss: 0.1951 - val_dice_coef: 0.8256\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0418 - dice_coef: 0.9107 - val_loss: 0.1791 - val_dice_coef: 0.8313\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0421 - dice_coef: 0.9109 - val_loss: 0.2033 - val_dice_coef: 0.8122\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0430 - dice_coef: 0.9078 - val_loss: 0.2424 - val_dice_coef: 0.7787\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0424 - dice_coef: 0.9104 - val_loss: 0.2132 - val_dice_coef: 0.8105\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0418 - dice_coef: 0.9107 - val_loss: 0.2085 - val_dice_coef: 0.8100\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0411 - dice_coef: 0.9131 - val_loss: 0.2289 - val_dice_coef: 0.7907\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0414 - dice_coef: 0.9119 - val_loss: 0.2179 - val_dice_coef: 0.8093\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0408 - dice_coef: 0.9131 - val_loss: 0.1990 - val_dice_coef: 0.8218\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0403 - dice_coef: 0.9142 - val_loss: 0.2385 - val_dice_coef: 0.7924\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0400 - dice_coef: 0.9146 - val_loss: 0.2100 - val_dice_coef: 0.8131\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0403 - dice_coef: 0.9149 - val_loss: 0.1957 - val_dice_coef: 0.8334\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0414 - dice_coef: 0.9113 - val_loss: 0.1993 - val_dice_coef: 0.8276\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0427 - dice_coef: 0.9095 - val_loss: 0.2024 - val_dice_coef: 0.8221\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0405 - dice_coef: 0.9141 - val_loss: 0.1900 - val_dice_coef: 0.8292\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0393 - dice_coef: 0.9162 - val_loss: 0.2050 - val_dice_coef: 0.8199\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0396 - dice_coef: 0.9159 - val_loss: 0.2273 - val_dice_coef: 0.8003\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0399 - dice_coef: 0.9150 - val_loss: 0.1880 - val_dice_coef: 0.8328\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0396 - dice_coef: 0.9160 - val_loss: 0.2140 - val_dice_coef: 0.8184\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0392 - dice_coef: 0.9165 - val_loss: 0.2012 - val_dice_coef: 0.8275\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0386 - dice_coef: 0.9185 - val_loss: 0.2098 - val_dice_coef: 0.8250\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0385 - dice_coef: 0.9170 - val_loss: 0.2065 - val_dice_coef: 0.8253\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0388 - dice_coef: 0.9185 - val_loss: 0.2261 - val_dice_coef: 0.8127\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0377 - dice_coef: 0.9193 - val_loss: 0.1968 - val_dice_coef: 0.8312\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0371 - dice_coef: 0.9211 - val_loss: 0.2281 - val_dice_coef: 0.8097\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0380 - dice_coef: 0.9187 - val_loss: 0.2177 - val_dice_coef: 0.8159\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0371 - dice_coef: 0.9208 - val_loss: 0.2049 - val_dice_coef: 0.8250\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0398 - dice_coef: 0.9159 - val_loss: 0.2630 - val_dice_coef: 0.7916\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0372 - dice_coef: 0.9204 - val_loss: 0.2032 - val_dice_coef: 0.8284\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0374 - dice_coef: 0.9206 - val_loss: 0.2173 - val_dice_coef: 0.8145\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0371 - dice_coef: 0.9214 - val_loss: 0.2508 - val_dice_coef: 0.7951\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0370 - dice_coef: 0.9208 - val_loss: 0.2309 - val_dice_coef: 0.8101\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0370 - dice_coef: 0.9219 - val_loss: 0.2177 - val_dice_coef: 0.8215\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0372 - dice_coef: 0.9205 - val_loss: 0.2052 - val_dice_coef: 0.8305\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0368 - dice_coef: 0.9212 - val_loss: 0.2010 - val_dice_coef: 0.8282\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0362 - dice_coef: 0.9230 - val_loss: 0.2186 - val_dice_coef: 0.8216\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0394 - dice_coef: 0.9182 - val_loss: 0.2257 - val_dice_coef: 0.8134\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0385 - dice_coef: 0.9181 - val_loss: 0.2030 - val_dice_coef: 0.8323\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0375 - dice_coef: 0.9199 - val_loss: 0.2060 - val_dice_coef: 0.8303\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0366 - dice_coef: 0.9217 - val_loss: 0.2386 - val_dice_coef: 0.8084\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0370 - dice_coef: 0.9211 - val_loss: 0.2224 - val_dice_coef: 0.8242\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0361 - dice_coef: 0.9231 - val_loss: 0.2120 - val_dice_coef: 0.8221\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0365 - dice_coef: 0.9224 - val_loss: 0.2221 - val_dice_coef: 0.8198\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0364 - dice_coef: 0.9224 - val_loss: 0.2211 - val_dice_coef: 0.8176\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0347 - dice_coef: 0.9261 - val_loss: 0.2089 - val_dice_coef: 0.8294\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0350 - dice_coef: 0.9258 - val_loss: 0.1945 - val_dice_coef: 0.8327\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0357 - dice_coef: 0.9241 - val_loss: 0.2203 - val_dice_coef: 0.8151\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0374 - dice_coef: 0.9208 - val_loss: 0.2408 - val_dice_coef: 0.8136\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0379 - dice_coef: 0.9202 - val_loss: 0.2029 - val_dice_coef: 0.8262\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0374 - dice_coef: 0.9206 - val_loss: 0.2056 - val_dice_coef: 0.8363\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0365 - dice_coef: 0.9224 - val_loss: 0.2085 - val_dice_coef: 0.8339\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0354 - dice_coef: 0.9248 - val_loss: 0.2410 - val_dice_coef: 0.8043\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0344 - dice_coef: 0.9263 - val_loss: 0.2104 - val_dice_coef: 0.8299\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0351 - dice_coef: 0.9250 - val_loss: 0.2126 - val_dice_coef: 0.8240\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0337 - dice_coef: 0.9277 - val_loss: 0.1943 - val_dice_coef: 0.8368\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0339 - dice_coef: 0.9277 - val_loss: 0.2212 - val_dice_coef: 0.8225\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0340 - dice_coef: 0.9277 - val_loss: 0.2443 - val_dice_coef: 0.8046\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0330 - dice_coef: 0.9289 - val_loss: 0.2169 - val_dice_coef: 0.8266\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0331 - dice_coef: 0.9296 - val_loss: 0.2330 - val_dice_coef: 0.8148\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0347 - dice_coef: 0.9265 - val_loss: 0.2272 - val_dice_coef: 0.8357\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0336 - dice_coef: 0.9275 - val_loss: 0.2091 - val_dice_coef: 0.8336\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0334 - dice_coef: 0.9288 - val_loss: 0.2182 - val_dice_coef: 0.8254\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0324 - dice_coef: 0.9306 - val_loss: 0.1977 - val_dice_coef: 0.8393\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0326 - dice_coef: 0.9304 - val_loss: 0.2243 - val_dice_coef: 0.8263\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0339 - dice_coef: 0.9286 - val_loss: 0.2285 - val_dice_coef: 0.8285\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0337 - dice_coef: 0.9267 - val_loss: 0.2153 - val_dice_coef: 0.8338\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0337 - dice_coef: 0.9288 - val_loss: 0.2169 - val_dice_coef: 0.8431\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0339 - dice_coef: 0.9278 - val_loss: 0.2124 - val_dice_coef: 0.8345\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0338 - dice_coef: 0.9283 - val_loss: 0.2320 - val_dice_coef: 0.8286\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0349 - dice_coef: 0.9249 - val_loss: 0.2161 - val_dice_coef: 0.8355\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0330 - dice_coef: 0.9294 - val_loss: 0.2371 - val_dice_coef: 0.8180\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0333 - dice_coef: 0.9287 - val_loss: 0.2518 - val_dice_coef: 0.8069\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0361 - dice_coef: 0.9258 - val_loss: 0.2415 - val_dice_coef: 0.8253\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0375 - dice_coef: 0.9206 - val_loss: 0.2798 - val_dice_coef: 0.7969\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0353 - dice_coef: 0.9245 - val_loss: 0.2304 - val_dice_coef: 0.8223\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0335 - dice_coef: 0.9279 - val_loss: 0.2191 - val_dice_coef: 0.8312\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0329 - dice_coef: 0.9298 - val_loss: 0.2009 - val_dice_coef: 0.8374\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0322 - dice_coef: 0.9310 - val_loss: 0.2433 - val_dice_coef: 0.8072\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0322 - dice_coef: 0.9309 - val_loss: 0.2075 - val_dice_coef: 0.8380\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0333 - dice_coef: 0.9303 - val_loss: 0.2252 - val_dice_coef: 0.8254\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0334 - dice_coef: 0.9282 - val_loss: 0.2111 - val_dice_coef: 0.8282\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0324 - dice_coef: 0.9302 - val_loss: 0.2195 - val_dice_coef: 0.8314\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0323 - dice_coef: 0.9314 - val_loss: 0.2038 - val_dice_coef: 0.8432\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0328 - dice_coef: 0.9292 - val_loss: 0.2221 - val_dice_coef: 0.8275\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0310 - dice_coef: 0.9343 - val_loss: 0.2045 - val_dice_coef: 0.8420\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0316 - dice_coef: 0.9331 - val_loss: 0.2307 - val_dice_coef: 0.8271\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0325 - dice_coef: 0.9304 - val_loss: 0.2147 - val_dice_coef: 0.8333\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0319 - dice_coef: 0.9324 - val_loss: 0.2478 - val_dice_coef: 0.8162\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0314 - dice_coef: 0.9323 - val_loss: 0.2321 - val_dice_coef: 0.8238\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0318 - dice_coef: 0.9320 - val_loss: 0.2174 - val_dice_coef: 0.8358\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0307 - dice_coef: 0.9347 - val_loss: 0.2240 - val_dice_coef: 0.8284\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0316 - dice_coef: 0.9325 - val_loss: 0.2324 - val_dice_coef: 0.8250\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0308 - dice_coef: 0.9338 - val_loss: 0.2418 - val_dice_coef: 0.8209\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 4s 202ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0305 - dice_coef: 0.9347 - val_loss: 0.2268 - val_dice_coef: 0.8388\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0311 - dice_coef: 0.9338 - val_loss: 0.2835 - val_dice_coef: 0.7967\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0322 - dice_coef: 0.9313 - val_loss: 0.2177 - val_dice_coef: 0.8340\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0301 - dice_coef: 0.9353 - val_loss: 0.2154 - val_dice_coef: 0.8400\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0306 - dice_coef: 0.9349 - val_loss: 0.2140 - val_dice_coef: 0.8410\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0310 - dice_coef: 0.9342 - val_loss: 0.2766 - val_dice_coef: 0.8019\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0317 - dice_coef: 0.9327 - val_loss: 0.2419 - val_dice_coef: 0.8261\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0321 - dice_coef: 0.9317 - val_loss: 0.2550 - val_dice_coef: 0.8133\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0308 - dice_coef: 0.9332 - val_loss: 0.3050 - val_dice_coef: 0.7824\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0335 - dice_coef: 0.9309 - val_loss: 0.2171 - val_dice_coef: 0.8354\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0345 - dice_coef: 0.9261 - val_loss: 0.2815 - val_dice_coef: 0.8098\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0341 - dice_coef: 0.9276 - val_loss: 0.2182 - val_dice_coef: 0.8416\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 4s 200ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0318 - dice_coef: 0.9312 - val_loss: 0.2145 - val_dice_coef: 0.8438\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 4s 201ms/step - batch: 9.0000 - size: 50.0000 - loss: 0.0304 - dice_coef: 0.9350 - val_loss: 0.2240 - val_dice_coef: 0.8300\n"
     ]
    }
   ],
   "source": [
    "umic.run_training(network = unet3d, save_folder = save_folder, folder = folder, \n",
    "                numtot = numtot,batchsize = batchsize, numvalid = numvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"\n",
    "# Here you can choose which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import cryovesnet\n",
    "#from keras import backend as K\n",
    "#K.set_image_data_format('channels_last')\n",
    "\n",
    "# import unetmic.unetmic as umic\n",
    "import cryovesnet.unetmic.unetmic.unetmic as umic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for bigger patch size 64^3\n",
    "#specifiy path to training data and to folder where to save training weights\n",
    "folder = '/mnt/data/Amin/Data/train_dataset_64_raw_neuron'\n",
    "save_folder = '/mnt/data/Amin/Data/cryo_learning_64_nad/'\n",
    "\n",
    "#specify number of training data, validation data, batch size\n",
    "numtot = 1600\n",
    "numvalid = 250\n",
    "batchsize = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/replica:0/task:0/device:GPU:0', '/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /replica:0/task:0/device:CPU:0 then broadcast to ('/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/backend.py:6818: StrategyBase.configure (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use `update_config_proto` instead.\n",
      "WARNING:tensorflow:From /home/amin/PycharmProjects/CryoVesNetNEW/cryovesnet/unetmic/unetmic/unetmic.py:265: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /home/amin/PycharmProjects/CryoVesNetNEW/cryovesnet/unetmic/unetmic/unetmic.py:265: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/tensorflow/python/distribute/v1/input_lib.py:197: DistributedIteratorV1.initialize (from tensorflow.python.distribute.v1.input_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the iterator's `initializer` property instead.\n",
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/distribute/distributed_training_utils_v1.py:328: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use `experimental_local_results` instead.\n",
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:batch_all_reduce: 58 all-reduces with algorithm = nccl, num_packs = 1\n",
      "Train on 64.0 steps, validate on 10.0 steps\n",
      "Epoch 1/200\n",
      " 1/64 [..............................] - ETA: 7:46 - batch: 0.0000e+00 - size: 1.0000 - loss: 2.4621 - dice_coef: 0.2955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 18:59:46.052388: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:192] cuptiSubscribe: error 35: CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2024-04-29 18:59:46.052426: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2024-04-29 18:59:46.052435: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1716] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/64 [..............................] - ETA: 54s - batch: 0.5000 - size: 1.0000 - loss: 2.5215 - dice_coef: 0.3082     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 18:59:46.689925: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2024-04-29 18:59:46.689963: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2024-04-29 18:59:46.689968: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1808] function cupti_interface_->Finalize()failed with error \n",
      "2024-04-29 18:59:46.711008: E tensorflow/core/profiler/internal/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 60s 840ms/step - batch: 31.5000 - size: 1.0000 - loss: 1.5434 - dice_coef: 0.3459 - val_loss: 12.0216 - val_dice_coef: 0.3761\n",
      "Epoch 2/200\n",
      "64/64 [==============================] - 52s 807ms/step - batch: 31.5000 - size: 1.0000 - loss: 1.1645 - dice_coef: 0.4324 - val_loss: 2.3566 - val_dice_coef: 0.3929\n",
      "Epoch 3/200\n",
      "64/64 [==============================] - 53s 832ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.9082 - dice_coef: 0.5094 - val_loss: 0.8046 - val_dice_coef: 0.5477\n",
      "Epoch 4/200\n",
      "64/64 [==============================] - 44s 687ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.7497 - dice_coef: 0.5628 - val_loss: 0.8636 - val_dice_coef: 0.4873\n",
      "Epoch 5/200\n",
      "64/64 [==============================] - 48s 751ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.6883 - dice_coef: 0.5875 - val_loss: 0.7039 - val_dice_coef: 0.4918\n",
      "Epoch 6/200\n",
      "64/64 [==============================] - 53s 832ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.6230 - dice_coef: 0.6175 - val_loss: 0.5928 - val_dice_coef: 0.5590\n",
      "Epoch 7/200\n",
      "64/64 [==============================] - 44s 689ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.5675 - dice_coef: 0.6401 - val_loss: 0.6530 - val_dice_coef: 0.5344\n",
      "Epoch 8/200\n",
      "64/64 [==============================] - 44s 689ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.5153 - dice_coef: 0.6643 - val_loss: 1.0066 - val_dice_coef: 0.4108\n",
      "Epoch 9/200\n",
      "64/64 [==============================] - 49s 764ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.5015 - dice_coef: 0.6743 - val_loss: 0.6089 - val_dice_coef: 0.5847\n",
      "Epoch 10/200\n",
      "64/64 [==============================] - 44s 689ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.4698 - dice_coef: 0.6874 - val_loss: 0.8104 - val_dice_coef: 0.5068\n",
      "Epoch 11/200\n",
      "64/64 [==============================] - 49s 765ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.4818 - dice_coef: 0.6864 - val_loss: 0.6916 - val_dice_coef: 0.6659\n",
      "Epoch 12/200\n",
      "64/64 [==============================] - 44s 692ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.4106 - dice_coef: 0.7191 - val_loss: 0.6167 - val_dice_coef: 0.6003\n",
      "Epoch 13/200\n",
      "64/64 [==============================] - 49s 771ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.3864 - dice_coef: 0.7347 - val_loss: 0.6417 - val_dice_coef: 0.6833\n",
      "Epoch 14/200\n",
      "64/64 [==============================] - 44s 696ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.3571 - dice_coef: 0.7491 - val_loss: 0.5995 - val_dice_coef: 0.6601\n",
      "Epoch 15/200\n",
      "64/64 [==============================] - 49s 774ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.3401 - dice_coef: 0.7591 - val_loss: 0.7820 - val_dice_coef: 0.7282\n",
      "Epoch 16/200\n",
      "64/64 [==============================] - 44s 692ms/step - batch: 31.5000 - size: 1.0000 - loss: 0.3245 - dice_coef: 0.7734 - val_loss: 0.6132 - val_dice_coef: 0.7207\n",
      "Epoch 17/200\n",
      "14/64 [=====>........................] - ETA: 31s - batch: 6.5000 - size: 1.0000 - loss: 0.3069 - dice_coef: 0.7804"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mumic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training_multiGPU\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msave_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_total\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumtot\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_valid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumvalid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/CryoVesNetNEW/cryovesnet/unetmic/unetmic/unetmic.py:277\u001b[0m, in \u001b[0;36mrun_training_multiGPU\u001b[0;34m(save_folder, data_folder, num_total, batch_size, num_valid, window_size)\u001b[0m\n\u001b[1;32m    270\u001b[0m     valid_data \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_generator(\u001b[38;5;28;01mlambda\u001b[39;00m: valid_generator(data_folder, num_valid, num_total, batch_size),\n\u001b[1;32m    271\u001b[0m                                                 output_types\u001b[38;5;241m=\u001b[39m(tf\u001b[38;5;241m.\u001b[39mfloat32, tf\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    272\u001b[0m                                                 output_shapes\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    273\u001b[0m                                                     [batch_size, window_size, window_size, window_size, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    274\u001b[0m                                                     [batch_size, window_size, window_size, window_size, \u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     network\u001b[38;5;241m.\u001b[39mfit(train_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, steps_per_epoch\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloor(num_total \u001b[38;5;241m/\u001b[39m batch_size),\n\u001b[1;32m    278\u001b[0m                 validation_data\u001b[38;5;241m=\u001b[39mvalid_data, validation_steps\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloor(num_valid \u001b[38;5;241m/\u001b[39m batch_size),\n\u001b[1;32m    279\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39m[model_checkpoint_dice, model_checkpoint_loss, csv_logger, tensorboard_callback])\n\u001b[1;32m    281\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/engine/training_v1.py:776\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    775\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 776\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/engine/training_distributed_v1.py:663\u001b[0m, in \u001b[0;36mDistributionSingleWorkerTrainingLoop.fit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# Run TPU training in a custom loop in graph mode.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m experimental_tpu_fit_loop(\n\u001b[1;32m    652\u001b[0m         model,\n\u001b[1;32m    653\u001b[0m         dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    660\u001b[0m         validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[1;32m    661\u001b[0m         validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq)\n\u001b[0;32m--> 663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtraining_arrays_v1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py:287\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     actual_inputs \u001b[38;5;241m=\u001b[39m ins()\n\u001b[0;32m--> 287\u001b[0m   batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    289\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_dataset:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# The dataset passed by the user ran out of batches.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;66;03m# Now we know the cardinality of the dataset.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# If steps_per_epoch was specified, then running out of data is\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# unexpected, so we stop training and inform the user.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/keras/backend.py:4284\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   4279\u001b[0m     symbol_vals \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol_vals \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   4280\u001b[0m     feed_symbols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_symbols \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetches \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   4281\u001b[0m     session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session):\n\u001b[1;32m   4282\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m-> 4284\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4285\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches):])\n\u001b[1;32m   4287\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   4288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[1;32m   4289\u001b[0m     fetched[:\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[1;32m   4290\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoVesNet/lib/python3.9/site-packages/tensorflow/python/client/session.py:1480\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1479\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1480\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1483\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m   1484\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "umic.run_training_multiGPU(save_folder = save_folder, data_folder = folder, \n",
    "                num_total = numtot,batch_size = batchsize, num_valid = numvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
