{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Creating training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebooks generates series of 32x32x32 volumes of both image and mask data of vesicles to create a training set for machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "\n",
    "from skimage.morphology import label as label\n",
    "from skimage.measure import regionprops as regprop\n",
    "from skimage.morphology import disk, binary_dilation\n",
    "\n",
    "import mrcfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #define location of data\n",
    "# server_path = '/Volumes/synaptosome/pyto/tomo/'\n",
    "# server_path = '/mnt/data/amin/Data/tomo/'\n",
    "# #define location where to save the training data \n",
    "# folder_to_save = '/Users/gw18g940/Desktop/Test_data/Zuber/multi_set_training/'\n",
    "# folder_to_save = '/mnt/data/amin/Data/train_dataset_nonad/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# server_path = '/mnt/data/amin/Handpicked/'\n",
    "server_path = '/mnt/data/Amin/tomo/'\n",
    "folder_to_save = '/mnt/data/Amin/Data/train_dataset_32_synaptasome_1024/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#find all folders containing data\n",
    "# folders = glob.glob(server_path+'*ctrl*')\n",
    "folders = glob.glob(server_path+'*')\n",
    "print(len(folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#in all folders, load both .rec and .mrc files. Use the cell contour to define a region to consider \n",
    "#for extraction of data (empty regions are not interesting)\n",
    "ind =0\n",
    "target_count= 1024*1\n",
    "stride= 32\n",
    "\n",
    "for f in folders:\n",
    "    \n",
    "    print(f)\n",
    "    if os.path.exists(f+'/labels-16bit.mrc'):\n",
    "        print(ind)\n",
    "        # print(glob.glob(f+'/*.rec.nad')[0])\n",
    "        \n",
    "        imagefile = mrcfile.open(glob.glob(f+'/*.rec.nad')[0])\n",
    "        maskfile = mrcfile.open(f+'/labels-16bit.mrc')\n",
    "\n",
    "        image = imagefile.data\n",
    "        mask = maskfile.data\n",
    "        \n",
    "        mask = mask >= 10\n",
    "        \n",
    "        # fig, ax = plt.subplots(figsize=(5,5))\n",
    "        # plt.imshow(image[100,:,:],cmap = 'gray')\n",
    "        # plt.imshow(mask[100,:,:], cmap = 'Reds', alpha = 0.1)\n",
    "        # plt.show()\n",
    "        \n",
    "        #dilate the cell mask \n",
    "        mask2d = binary_dilation(np.sum(mask,axis = 0)>0,disk(20))>0\n",
    "        \n",
    "        #split the volume into 32x32x32 volumes. Keep only volumes occupied \n",
    "        #by a sufficient amount of vesicles (1000 voxels)\n",
    "        for z in np.arange(0,image.shape[0]-stride,stride):\n",
    "            for x in np.arange(0,image.shape[1]-stride,stride):\n",
    "                for y in np.arange(0,image.shape[2]-stride,stride):\n",
    "                    if np.sum(mask[z:z+stride,x:x+stride,y:y+stride])>target_count:\n",
    "                        np.save(folder_to_save+'image_'+str(ind)+'.npy',\n",
    "                       image[z:z+stride, x:x+stride,y:y+stride].astype(np.float32))\n",
    "\n",
    "                        np.save(folder_to_save+'mask_'+str(ind)+'.npy',\n",
    "                       mask[z:z+stride, x:x+stride,y:y+stride].astype(np.float32))\n",
    "                        ind+=1\n",
    "print(ind-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = 2\n",
    "\n",
    "image = np.load(folder_to_save+'image_'+str(index)+'.npy')\n",
    "mask = np.load(folder_to_save+'mask_'+str(index)+'.npy')\n",
    "plt.imshow(image[25,:,:], cmap = 'gray')\n",
    "plt.imshow(mask[25,:,:], cmap = 'Reds', alpha = 0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.sum(mask[:,:,:],axis = 0), cmap = 'Reds')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating training set for 2D networks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# server_path = '/mnt/data/amin/Handpicked/'\n",
    "server_path = '/mnt/data/Amin/tomo/'\n",
    "folder_to_save = '/mnt/data/Amin/Data_latest/train_dataset_1axes_2d_64_synaptasome_128/'\n",
    "# folder_to_save = '/media/amin/mtwo/train_dataset_2d_128_synaptasome_512/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all folders containing data\n",
    "# folders = glob.glob(server_path+'*ctrl*')\n",
    "folders = glob.glob(server_path+'*')\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#in all folders, load both .rec and .mrc files. Use the cell contour to define a region to consider \n",
    "#for extraction of data (empty regions are not interesting)\n",
    "ind =0\n",
    "num_validation_data = 2\n",
    "target_count= 128\n",
    "\n",
    "for i, f in enumerate(folders):\n",
    "    print(f)\n",
    "    if os.path.exists(f+'/labels-16bit.mrc'):\n",
    "        print(ind)\n",
    "        print(glob.glob(f+'/*.rec.nad')[0])\n",
    "        \n",
    "        imagefile = mrcfile.open(glob.glob(f+'/*.rec.nad')[0])\n",
    "        maskfile = mrcfile.open(f+'/labels-16bit.mrc')\n",
    "\n",
    "        image = imagefile.data\n",
    "        mask = maskfile.data\n",
    "        \n",
    "        mask = mask >= 10\n",
    "        \n",
    "        # fig, ax = plt.subplots(figsize=(5,5))\n",
    "        # plt.imshow(image[100,:,:],cmap = 'gray')\n",
    "        # plt.imshow(mask[100,:,:], cmap = 'Reds', alpha = 0.1)\n",
    "        # plt.show()\n",
    "        \n",
    "        #dilate the cell mask \n",
    "        # mask2d = binary_dilation(np.sum(mask,axis = 0)>0,disk(20))>0\n",
    "        \n",
    "        #split the volume into 32x32x32 volumes. Keep only volumes occupied \n",
    "        #by a sufficient amount of vesicles (1000 voxels)\n",
    "        stride=64\n",
    "        for z in np.arange(0,image.shape[0]):\n",
    "            for x in np.arange(0,image.shape[1]-stride,stride):\n",
    "                for y in np.arange(0,image.shape[2]-stride,stride):\n",
    "                    if np.sum(mask[z,x:x+stride,y:y+stride])>target_count:\n",
    "                        np.save(folder_to_save+'image_'+str(ind)+'.npy',\n",
    "                       image[z, x:x+stride,y:y+stride].astype(np.float32))\n",
    "\n",
    "                        np.save(folder_to_save+'mask_'+str(ind)+'.npy',\n",
    "                       mask[z, x:x+stride,y:y+stride].astype(np.float32))\n",
    "                        ind+=1\n",
    "        if i == (len(folders) - 1):\n",
    "            print(\"Val Datasize: \", ind - train_dataset_size)\n",
    "        if i == (len(folders) - num_validation_data - 1):\n",
    "            print(\"Train Datasize: \",ind)\n",
    "            train_dataset_size = ind\n",
    "        if True or i > (len(folders) - num_validation_data - 1):\n",
    "            print(i,f)\n",
    "            continue\n",
    "        for y in np.arange(0,image.shape[2]):\n",
    "            for x in np.arange(0,image.shape[1]-stride,stride):\n",
    "                for z in np.arange(0,image.shape[0]-stride,stride):\n",
    "                    if np.sum(mask[z:z+stride,x:x+stride,y])>target_count:\n",
    "                        np.save(folder_to_save+'image_'+str(ind)+'.npy',\n",
    "                       image[z:z+stride,x:x+stride,y].astype(np.float32))\n",
    "\n",
    "                        np.save(folder_to_save+'mask_'+str(ind)+'.npy',\n",
    "                       mask[z:z+stride,x:x+stride,y].astype(np.float32))\n",
    "                        ind+=1\n",
    "        for x in np.arange(0,image.shape[1]):\n",
    "            for z in np.arange(0,image.shape[0]-stride,stride):\n",
    "                for y in np.arange(0,image.shape[2]-stride,stride):\n",
    "                    if np.sum(mask[z:z+stride,x,y:y+stride])>target_count:\n",
    "                        np.save(folder_to_save+'image_'+str(ind)+'.npy',\n",
    "                       image[z:z+stride,x,y:y+stride].astype(np.float32))\n",
    "\n",
    "                        np.save(folder_to_save+'mask_'+str(ind)+'.npy',\n",
    "                       mask[z:z+stride,x,y:y+stride].astype(np.float32))\n",
    "                        ind+=1\n",
    "        if i == (len(folders) - num_validation_data - 1):\n",
    "            print(\"Train Datasize: \",ind)\n",
    "            train_dataset_size = ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
